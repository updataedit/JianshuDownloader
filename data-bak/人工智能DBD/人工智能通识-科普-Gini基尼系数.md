欢迎关注我的专栏( つ•̀ω•́)つ[【人工智能通识】](https://www.jianshu.com/c/e9a7b7b7024d)
[【汇总】2019年4月专题](https://www.jianshu.com/p/e1afed853866)

---

经济学中的基尼系数和决策树中的基尼杂质（不纯度）是不同的概念。

![](imgs/4324074-83e062ed4b432049.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)




##基尼系数Gini coefficient

基尼指标Gini index或基尼系数Gini coefficient是意大利统计学家科拉多·基尼Corrado Gini在1912年制定的分布的统计指标。

也有硬把基尼指标称为基尼指数的，从英文上看index和指数无关，应该是翻译的笔误成为习惯了吧。

基尼系数通常被用来衡量经济不平等或收入分配，或者不均匀的财富分配。

基尼系数范围从0（或0％）到1（或100％），0表示完全均衡，1表示完全不均衡。但理论上讲，由于负收入或负财富，超过1的值是可能的。

一个国家，如果每个人的都收入都相等，基尼系数就是0，最均等；如果这个国家1个人拥有全部财富，而其他所有人都一无所有，那么基尼系数就变为1，最不均等。

![](imgs/4324074-0594d56a8993bbdb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

从上图可以理解基尼系数的数学含义。横向是人口百分比例，从左侧0个人到右侧100%全国人口；竖向是人口所对应的财富占比。比如说图中深蓝色线玻利维亚Bolivia国家的50%人口拥有19.52%的财富；而在海地Haiti这个国家同样50%的人口却只拥有11.89%的财富（图中未标示）；感性上说玻利维亚更均等些。

如果某个国家的财富分布是最上面的浅蓝色直线那样，那么它正好是50%的人拥有50%的财富，60%的人拥有60%的财富...人均财富相等的完美状态。


基尼系数就是指完美均等斜线下面的面积L，减去曲线下的面积C，然后再除以A的值，即:

$$GiniCoefficient=\frac{AreaBelowLine-AreaBelowCurve}{AreaBelowLine}$$

很明显它的值在0到1之间，0即表示和直线重合，1就是极端不均等状态。

![](imgs/4324074-f90528dfa411442c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

>这条描述人口和财富比例变化的曲线就叫做洛伦兹曲线，它是美国经济学家马克斯洛伦兹在1905年创造的。

##错误分类率Incorrect Classification

假设我们有三种水果共12个，其中三个苹果Apple，三个香蕉Banana，六个樱桃Cherry，表示为下：

$$A_1,A_2,A_3,B_1,B_2,B_3,C_1,C_2,C_3,C_4,C_5,C_6$$

如果我们从其中取出任意一个草莓，然后随机的给它贴一个种类标签，“苹果”，“香蕉”或者“草莓”，那么，我贴错的可能性是多少？——我有50%的可能性贴错，或者是我有$\frac{6}{12}$可能贴对。

同样，任意取一个苹果，随机贴标签，错误的概率就大很多，$\frac{9}{12}$会搞错，取香蕉任意贴的错误率也是$\frac{9}{12}$。

好了，我们在考虑任意在12个水果里面取一个，会取到樱桃的概率是多少？$\frac{6}{12}$，一半的概率。同样取到苹果或者香蕉的概率都是$\frac{3}{12}$。

综上，对于3个A，3个B和6个C的一组数据，随机分类的错误率是下面的算式：

$$\frac{3}{12}\times \frac{9}{12}+\frac{3}{12}\times \frac{9}{12}+\frac{6}{12}\times \frac{6}{12}$$

先不急着计算，仔细看就会注意到$\frac{3}{12}=1- \frac{9}{12}$，$\frac{6}{12}=1- \frac{6}{12}$，这意味着，某个种被随机贴错标签的概率$P_k$等于1减去这个种类可能被随机取到概率$P_i$，即：

$$P_k=1- P_i$$


##基尼杂质Gini Impurity

在机器学习中提及的Gini基尼其实是指基尼杂质Gini Impurity或者说是基尼不纯度，当然也经常被稀里糊涂的称之为基尼系数Gini index。

![](imgs/4324074-59d9e23f035ab39f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


在这里，基尼杂质就是指所有分类的可能错误分类率之和，按照上面水果的例子来说，就是上面的算式的结果：

$$
\begin{align}
&\frac{3}{12}\times \frac{9}{12}+\frac{3}{12}\times \frac{9}{12}+\frac{6}{12}\times \frac{6}{12}\\
&=\frac{1}{4}\times \frac{3}{4}+\frac{1}{4}\times \frac{3}{4}+\frac{1}{2}\times \frac{1}{2}\\
&=\frac{6}{16}+\frac{4}{10}\\
&=\frac{10}{16}\\
&=0.625\\
\end{align}
$$

计算基尼杂质的公式就是将所有分类占比$P_i$乘以分类错误率$P_k$之积叠加：

$$Gini(P)=\sum_{i=1}^{J}P_i\sum_{k\neq i}P_k$$

这里的J是指所有可能分类的总数，即有J个种类，在上面水果分类中J=3。这里的k表示的是错误贴上去的标签。

我们接下来对这个公式简化一下：

$$
\begin{align}
Gini(P)&=\sum_{i=1}^{J}P_i\sum_{k\neq i}P_k\\
&=\sum_{i=1}^{J}P_i(1-P_i)\\
&=\sum_{i=1}^{J}(P_i-P_i^2)\\
&=\sum_{i=1}^{J}P_i-\sum_{i=1}^{J}P_i^2\\
&=1-\sum_{i=1}^{J}P_i^2 \\
\end{align}
$$

注意:
- 利用了我们上面说到的$P_k=1-P_i$;
- $\sum_{i=1}^{J}P_i=1$,苹果、香蕉、樱桃所有种类的可能性之和当然是1;

最后我们把基尼杂质公式写下来就是：

$$Gini(P)=1-\sum_{i=1}^{J}P_i^2 $$

怎么讲？还是以12水果的例子来看：
$$
\begin{align}
Gini(水果)&=1-\sum_{i=1}^{J}P_i^2\\
&=1-((\frac{3}{12})^2+(\frac{3}{12})^2+(\frac{6}{12})^2)\\
&=1-((\frac{1}{4})^2+(\frac{1}{4})^2+(\frac{1}{2})^2)\\
&=1-(\frac{1}{16}+\frac{1}{16}+\frac{4}{16})\\
&=1-\frac{6}{12}\\
&=1-\frac{10}{12}\\
&=0.625
\end{align}
$$

与我们上面的方法一致。

##属性的基尼杂质

![](imgs/4324074-703e5e9ffb567664.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上面我们计算的是系统最终输出的基尼杂质，下面我们来看一下在上一篇[信息增益-3](https://www.jianshu.com/p/7272fb013d99)中的女生择偶数据的例子：

![](imgs/4324074-e072ac05b3acf596.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

“颜值属性”的基尼杂质怎么计算？
我们从基尼杂质的基本概念出发，先看颜值高的分类情况：

- 颜值只有两个类别，高或低；
- 共8个高颜值，随机选一个，选中高的概率$P_高=\frac{8}{12}$；
- 选到高，然后随机贴，50%概率贴“嫁”，有5个搞错，那么错误率是$P_{高\times嫁}=\frac{5}{8}$
- 选到高，然后随机贴，50%概率贴“否”，有3个搞错，那么错误率是$P_{高\times否}=\frac{3}{8}$

所以高分类的分类错误率是：

$$\frac{8}{12}\times (\frac{1}{2}\times\frac{5}{8}+\frac{1}{2}\times\frac{3}{8})=\frac{8}{12}\times\frac{1}{2}=0.333$$

我们再看颜值低的分类情况：

- 共4个低颜值，随机选一个，选中低的概率$P_高=\frac{4}{12}$；
- 选到低，然后随机贴，50%概率贴“嫁”，有1个搞错，那么错误率是$P_{高\times嫁}=\frac{1}{4}$
- 选到高，然后随机贴，50%概率贴“否”，有3个搞错，那么错误率是$P_{高\times否}=\frac{3}{4}$

所以低分类的分类错误率是：

$$\frac{4}{12}\times \frac{1}{2}=0.333$$

所以总的基尼杂质是：

$$Gini(择偶,颜值)=0.333+0.333=0.666$$

注意，基尼杂质越高就代表越容易分类错误，也就越不好，所以应该优先选择杂质低的属性作为决策树的上层分类节点。

>基尼杂质和AUC、ROC指标有着很多相似特性，后续我们再继续学习。

---
欢迎关注我的专栏( つ•̀ω•́)つ[【人工智能通识】](https://www.jianshu.com/c/e9a7b7b7024d)

---
###每个人的智能新时代
如果您发现文章错误，请不吝留言指正；
如果您觉得有用，请点喜欢；
如果您觉得很有用，欢迎转载~
---
END